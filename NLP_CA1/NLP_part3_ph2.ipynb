{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zs7Ld2iJfXq6",
        "outputId": "0014be64-95da-4163-9ebf-fa87c883efd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(('of', 'the'), 958), (('in', 'the'), 347), (('to', 'the'), 306), (('Ibn', 'Jad'), 226), (('and', 'the'), 189), (('upon', 'the'), 153), (('from', 'the'), 149), (('he', 'had'), 135), (('of', 'his'), 133), (('that', 'he'), 121)]\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "\n",
        "with open(\"Tarzan.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    corpus = file.read()\n",
        "clean_text = re.sub(r\"[^\\w\\s]\", \"\", corpus).replace('\\ufeff', '')\n",
        "token = word_tokenize(clean_text, language='english')\n",
        "bigrams = list(ngrams(token, 2))\n",
        "freq= nltk.FreqDist(bigrams)\n",
        "top_10_pairs = freq.most_common(10)\n",
        "print(top_10_pairs)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "word_freq = nltk.FreqDist(token)\n",
        "unique_words = list(set(token))\n",
        "co_occurrence_matrix = np.zeros((len(unique_words), len(unique_words)), dtype=float)\n",
        "for i, word1 in enumerate(unique_words):\n",
        "    for j, word2 in enumerate(unique_words):\n",
        "        if i == j:\n",
        "            co_occurrence_matrix[i, j] = 0.01\n",
        "        co_occurrence_matrix[i, j] = freq.get((word1, word2), 0.01)\n",
        "co_occurrence_df = pd.DataFrame(co_occurrence_matrix, index=unique_words, columns=unique_words)"
      ],
      "metadata": {
        "id": "ZUgau24zkKTS"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ten_words_co_occurrence_df_smoothed = co_occurrence_df.iloc[:5, :5]\n",
        "print(ten_words_co_occurrence_df_smoothed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyWR5pQUqJgH",
        "outputId": "db9706aa-5708-47f8-970e-cc3490e01100"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             lances  wealth  novelty  wheresoever  void\n",
            "lances         0.01    0.01     0.01         0.01  0.01\n",
            "wealth         0.01    0.01     0.01         0.01  0.01\n",
            "novelty        0.01    0.01     0.01         0.01  0.01\n",
            "wheresoever    0.01    0.01     0.01         0.01  0.01\n",
            "void           0.01    0.01     0.01         0.01  0.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prob_co_occurrence_matrix = np.zeros((len(unique_words), len(unique_words)), dtype=float)\n",
        "\n",
        "for i, word in enumerate(unique_words):\n",
        "    word_total = co_occurrence_matrix[i, :].sum() + len(unique_words)\n",
        "    prob_co_occurrence_matrix[i, :] = co_occurrence_matrix[i, :] / word_total\n",
        "\n",
        "prob_co_occurrence_df = pd.DataFrame(prob_co_occurrence_matrix, index=unique_words, columns=unique_words)\n",
        "ten_words_prob_co_occurrence_df = prob_co_occurrence_df.iloc[:5, :5]\n",
        "print(ten_words_prob_co_occurrence_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIExIeCJrGg0",
        "outputId": "f9ec19bb-8ae0-48a6-e025-82d38d3e8ac2"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               lances    wealth   novelty  wheresoever      void\n",
            "lances       0.000001  0.000001  0.000001     0.000001  0.000001\n",
            "wealth       0.000001  0.000001  0.000001     0.000001  0.000001\n",
            "novelty      0.000001  0.000001  0.000001     0.000001  0.000001\n",
            "wheresoever  0.000001  0.000001  0.000001     0.000001  0.000001\n",
            "void         0.000001  0.000001  0.000001     0.000001  0.000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next_word_after_i = prob_co_occurrence_df.loc['I'].idxmax()\n",
        "highest_probability_after_i = prob_co_occurrence_df.loc['I'].max()\n",
        "print(f'The word most likely to follow \"I\" is \"{next_word_after_i}\" with a probability of {highest_probability_after_i:.4f}')\n",
        "\n",
        "next_word_after_want = prob_co_occurrence_df.loc['want'].idxmax()\n",
        "highest_probability_after_want = prob_co_occurrence_df.loc['want'].max()\n",
        "print(f'The word most likely to follow \"want\" is \"{next_word_after_want}\" with a probability of {highest_probability_after_want:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIokpkJIr-r9",
        "outputId": "5739ab7c-b987-4d33-f4fd-4a2c272320f0"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The word most likely to follow \"I\" is \"am\" with a probability of 0.0086\n",
            "The word most likely to follow \"want\" is \"to\" with a probability of 0.0014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "sentence = \"For half a day he lolled on the huge back and\"\n",
        "sentence_tokens = word_tokenize(sentence.lower())\n",
        "for _ in range(10):\n",
        "    last_word = sentence_tokens[-1]\n",
        "    if last_word in prob_co_occurrence_df.index:\n",
        "        next_word_probs = prob_co_occurrence_df.loc[last_word]\n",
        "        top_next_words = next_word_probs.nlargest(10)\n",
        "        next_word = random.choice(top_next_words.index.tolist())\n",
        "        sentence_tokens.append(next_word)\n",
        "    else:\n",
        "        break\n",
        "extended_sentence = ' '.join(sentence_tokens)\n",
        "\n",
        "print(\"Generated sentence (with random choice from top 10):\", extended_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AssEHZX_sMwt",
        "outputId": "56d7a64d-9a05-4bf4-d6eb-b31d512027ac"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated sentence (with random choice from top 10): for half a day he lolled on the huge back and so they saw his sword was to them that it\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "sentence = \"For half a day he lolled on the huge back and\"\n",
        "sentence_tokens = sentence.lower().split()\n",
        "for _ in range(10):\n",
        "    last_word = sentence_tokens[-1]\n",
        "    if last_word in prob_co_occurrence_df.index:\n",
        "        next_word_probs = prob_co_occurrence_df.loc[last_word]\n",
        "        next_word_probs /= next_word_probs.sum()\n",
        "        potential_next_words = next_word_probs.index.tolist()\n",
        "        probabilities = next_word_probs.values\n",
        "        random_number = random.random()\n",
        "        cumulative_probability = 0.0\n",
        "        for i, probability in enumerate(probabilities):\n",
        "            cumulative_probability += probability\n",
        "            if random_number < cumulative_probability:\n",
        "                next_word = potential_next_words[i]\n",
        "                break\n",
        "        sentence_tokens.append(next_word)\n",
        "    else:\n",
        "        break\n",
        "    sentence = ' '.join(sentence_tokens)\n",
        "print(\"Generated sentence:\", sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJyr0dkiujmz",
        "outputId": "0162b016-1768-4e3d-9962-ddb3fe9e1097"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated sentence: for half a day he lolled on the huge back and it was gone battle space hat jest board stout patch\n"
          ]
        }
      ]
    }
  ]
}